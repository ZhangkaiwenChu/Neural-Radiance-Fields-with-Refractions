{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8096bd69-06cb-45ba-947b-9256fc000e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import imageio\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "997f21e3-98fa-4606-99f9-3c6cba80f83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_llff import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b186f6-12f6-4b15-ae60-61a66d731af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "np.random.seed(0)\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c1e80f-d942-48c1-9df5-3bc1b1d9d0f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0efb0e76-9a75-438b-bc6e-104cacef9cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = config_parser()\n",
    "args = parser.parse_args('--config C:/Users/chuzh/Study/CIS565/final/Neural-Radiance-Fields-with-Refractions/code/configs/fern.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb528a90-b17b-49a8-a355-dded4ed64c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image data (378, 504, 3, 20) [378.         504.         407.56579161]\n",
      "Loaded ./data/nerf_llff_data/fern 16.985296178676084 80.00209740336334\n",
      "recentered (3, 5)\n",
      "[[ 1.0000000e+00  0.0000000e+00  0.0000000e+00  1.4901161e-09]\n",
      " [ 0.0000000e+00  1.0000000e+00 -1.8730975e-09 -9.6857544e-09]\n",
      " [-0.0000000e+00  1.8730975e-09  1.0000000e+00  0.0000000e+00]]\n",
      "Data:\n",
      "(20, 3, 5) (20, 378, 504, 3) (20, 2)\n",
      "HOLDOUT view is 12\n",
      "Loaded llff (20, 378, 504, 3) (120, 3, 5) [378.     504.     407.5658] ./data/nerf_llff_data/fern\n",
      "Auto LLFF holdout, 8\n",
      "DEFINING BOUNDS\n",
      "NEAR FAR 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "K = None\n",
    "if args.dataset_type == 'llff':\n",
    "    images, poses, bds, render_poses, i_test = load_llff_data(args.datadir, args.factor,\n",
    "                                                                  recenter=True, bd_factor=.75,\n",
    "                                                                  spherify=args.spherify)\n",
    "    hwf = poses[0,:3,-1]\n",
    "    poses = poses[:,:3,:4]\n",
    "    print('Loaded llff', images.shape, render_poses.shape, hwf, args.datadir)\n",
    "    if not isinstance(i_test, list):\n",
    "        i_test = [i_test]\n",
    "\n",
    "    if args.llffhold > 0:\n",
    "        print('Auto LLFF holdout,', args.llffhold)\n",
    "        i_test = np.arange(images.shape[0])[::args.llffhold]\n",
    "\n",
    "    i_val = i_test\n",
    "    i_train = np.array([i for i in np.arange(int(images.shape[0])) if\n",
    "                        (i not in i_test and i not in i_val)])\n",
    "\n",
    "    print('DEFINING BOUNDS')\n",
    "    if args.no_ndc:\n",
    "        near = np.ndarray.min(bds) * .9\n",
    "        far = np.ndarray.max(bds) * 1.\n",
    "            \n",
    "    else:\n",
    "        near = 0.\n",
    "        far = 1.\n",
    "    print('NEAR FAR', near, far)\n",
    "\n",
    "elif args.dataset_type == 'blender':\n",
    "    images, poses, render_poses, hwf, i_split = load_blender_data(args.datadir, args.half_res, args.testskip)\n",
    "    print('Loaded blender', images.shape, render_poses.shape, hwf, args.datadir)\n",
    "    i_train, i_val, i_test = i_split\n",
    "\n",
    "    near = 2.\n",
    "    far = 6.\n",
    "\n",
    "    if args.white_bkgd:\n",
    "        images = images[...,:3]*images[...,-1:] + (1.-images[...,-1:])\n",
    "    else:\n",
    "        images = images[...,:3]\n",
    "\n",
    "elif args.dataset_type == 'LINEMOD':\n",
    "    images, poses, render_poses, hwf, K, i_split, near, far = load_LINEMOD_data(args.datadir, args.half_res, args.testskip)\n",
    "    print(f'Loaded LINEMOD, images shape: {images.shape}, hwf: {hwf}, K: {K}')\n",
    "    print(f'[CHECK HERE] near: {near}, far: {far}.')\n",
    "    i_train, i_val, i_test = i_split\n",
    "\n",
    "    if args.white_bkgd:\n",
    "        images = images[...,:3]*images[...,-1:] + (1.-images[...,-1:])\n",
    "    else:\n",
    "        images = images[...,:3]\n",
    "\n",
    "elif args.dataset_type == 'deepvoxels':\n",
    "\n",
    "    images, poses, render_poses, hwf, i_split = load_dv_data(scene=args.shape,\n",
    "                                                                 basedir=args.datadir,\n",
    "                                                                 testskip=args.testskip)\n",
    "\n",
    "    print('Loaded deepvoxels', images.shape, render_poses.shape, hwf, args.datadir)\n",
    "    i_train, i_val, i_test = i_split\n",
    "\n",
    "    hemi_R = np.mean(np.linalg.norm(poses[:,:3,-1], axis=-1))\n",
    "    near = hemi_R-1.\n",
    "    far = hemi_R+1.\n",
    "\n",
    "else:\n",
    "    print('Unknown dataset type', args.dataset_type, 'exiting')\n",
    "\n",
    "# Cast intrinsics to right types\n",
    "H, W, focal = hwf\n",
    "H, W = int(H), int(W)\n",
    "hwf = [H, W, focal]\n",
    "\n",
    "if K is None:\n",
    "    K = np.array([\n",
    "        [focal, 0, 0.5*W],\n",
    "        [0, focal, 0.5*H],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "if args.render_test:\n",
    "    render_poses = np.array(poses[i_test])\n",
    "\n",
    "# Create log dir and copy the config file\n",
    "basedir = args.basedir\n",
    "expname = args.expname\n",
    "os.makedirs(os.path.join(basedir, expname), exist_ok=True)\n",
    "f = os.path.join(basedir, expname, 'args.txt')\n",
    "with open(f, 'w') as file:\n",
    "    for arg in sorted(vars(args)):\n",
    "        attr = getattr(args, arg)\n",
    "        file.write('{} = {}\\n'.format(arg, attr))\n",
    "if args.config is not None:\n",
    "    f = os.path.join(basedir, expname, 'config.txt')\n",
    "    with open(f, 'w') as file:\n",
    "        file.write(open(args.config, 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af6309-5650-43be-8acd-ae85715e0882",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a996f3-9fbf-4fa6-b04f-07483c338697",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_rand = args.N_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5f3d27-f322-45fe-9330-107897cf0953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get rays\n",
      "done, concats\n",
      "shuffle rays\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('get rays')\n",
    "rays = np.stack([get_rays_np(H, W, K, p) for p in poses[:,:3,:4]], 0) # [N, ro+rd, H, W, 3]\n",
    "print('done, concats')\n",
    "rays_rgb = np.concatenate([rays, images[:,None]], 1) # [N, ro+rd+rgb, H, W, 3]\n",
    "rays_rgb = np.transpose(rays_rgb, [0,2,3,1,4]) # [N, H, W, ro+rd+rgb, 3]\n",
    "rays_rgb = np.stack([rays_rgb[i] for i in i_train], 0) # train images only\n",
    "rays_rgb = np.reshape(rays_rgb, [-1,3,3]) # [(N-1)*H*W, ro+rd+rgb, 3]\n",
    "rays_rgb = rays_rgb.astype(np.float32)\n",
    "print('shuffle rays')\n",
    "np.random.shuffle(rays_rgb)\n",
    "\n",
    "print('done')\n",
    "i_batch = 0\n",
    "\n",
    "images = torch.Tensor(images).to(device)\n",
    "poses = torch.Tensor(poses).to(device)\n",
    "rays_rgb = torch.Tensor(rays_rgb).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4579e44d-b387-403d-941b-4cb800c5e66c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a117b51-1c75-4c58-8cb2-fddfa4e36961",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeRF(nn.Module):\n",
    "    def __init__(self, in_pos = 3, in_view = 3, hidden = 256):\n",
    "        super(NeRF, self).__init__()\n",
    "        self.in_pos = in_pos\n",
    "        self.in_view = in_view\n",
    "        self.l1 = nn.Linear(in_pos, hidden)\n",
    "        self.l2 = nn.Linear(hidden, hidden)\n",
    "        self.l3 = nn.Linear(hidden, hidden)\n",
    "        self.l4 = nn.Linear(hidden, hidden)        \n",
    "        self.l5 = nn.Linear(in_pos + hidden, hidden)\n",
    "        self.l6 = nn.Linear(hidden, hidden)    \n",
    "        self.l7 = nn.Linear(hidden, hidden)   \n",
    "        self.l8 = nn.Linear(hidden, hidden)   \n",
    "        self.l9 = nn.Linear(hidden, hidden)   \n",
    "        self.l0 = nn.Linear(hidden + in_view, hidden//2)\n",
    "        self.rgb = nn.Linear(hidden//2, 3)\n",
    "        self.sigma = nn.Linear(hidden, 1)\n",
    "        self.r = nn.ReLU()\n",
    "        self.s = nn.Sigmoid()\n",
    "        \n",
    "        self.o1 = nn.Linear(in_pos + in_view, hidden)\n",
    "        self.o2 = nn.Linear(hidden, hidden)\n",
    "        self.o3 = nn.Linear(hidden, hidden)\n",
    "        self.o4 = nn.Linear(in_pos + in_view + hidden, hidden)\n",
    "        self.o5 = nn.Linear(hidden, hidden)\n",
    "        self.o6 = nn.Linear(hidden, hidden//2)\n",
    "        self.out = nn.Linear(hidden//2, 3)\n",
    "    \n",
    "    def nerf(self, pos,view):\n",
    "        out = self.r(self.l1(pos))\n",
    "        out = self.r(self.l2(out))\n",
    "        out = self.r(self.l3(out))\n",
    "        out = self.r(self.l4(out))\n",
    "        out = self.r(self.l5(torch.cat([pos, out], -1)))\n",
    "        out = self.r(self.l6(out))\n",
    "        out = self.r(self.l7(out))\n",
    "        out = self.r(self.l8(out))\n",
    "        sigma = self.sigma(out)\n",
    "        out = self.l9(out)\n",
    "        out = self.r(self.l0(torch.cat([view, out], -1)))\n",
    "        rgb = self.s(self.rgb(out))\n",
    "        return torch.cat([rgb, sigma], -1)\n",
    "    \n",
    "    def offset(self, x):\n",
    "        pos, view = torch.split(x, [self.in_pos, self.in_view], dim=-1)\n",
    "        out = self.r(self.o1(x))\n",
    "        out = self.r(self.o2(out))\n",
    "        out = self.r(self.o3(out))\n",
    "        out = self.r(self.o4(torch.cat([x, out], -1)))\n",
    "        out = self.r(self.o5(out))\n",
    "        out = self.r(self.o6(out))\n",
    "        out = self.out(out)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pos, view = torch.split(x, [self.in_pos, self.in_view], dim=-1)\n",
    "        offset = self.offset(x)\n",
    "        return self.nerf(pos + offset, view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9a903-39a1-4b58-a510-72d5c45cc9f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Render Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ca59834-0afd-45a1-9de7-d41fa13bb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(H, W, K, chunk = 1024*32, rays = None, c2w = None, ndc = True, near = 0., far = 1., **kwargs):\n",
    "    if c2w is not None:\n",
    "        rays_o, rays_d = get_rays(H, W, K, c2w)\n",
    "    else:\n",
    "        rays_o, rays_d = rays\n",
    "        \n",
    "    viewdirs = rays_d\n",
    "    viewdirs = viewdirs / torch.norm(viewdirs, dim=-1, keepdim=True)\n",
    "    viewdirs = torch.reshape(viewdirs, [-1,3]).float()\n",
    "    \n",
    "    shape = rays_d.shape\n",
    "    if ndc:\n",
    "        rays_o, rays_d = ndc_rays(H, W, K[0][0], 1., rays_o, rays_d)\n",
    "    \n",
    "    rays_o = torch.reshape(rays_o, [-1,3]).float()\n",
    "    rays_d = torch.reshape(rays_d, [-1,3]).float()\n",
    "    \n",
    "    near, far = near * torch.ones_like(rays_d[...,:1]), far * torch.ones_like(rays_d[...,:1])\n",
    "    rays = torch.cat([rays_o, rays_d, near, far], -1)\n",
    "    rays = torch.cat([rays, viewdirs], -1)\n",
    "    \n",
    "    all_ret = batchify_rays(rays, chunk, **kwargs)\n",
    "    for k in all_ret:\n",
    "        k_sh = list(shape[:-1]) + list(all_ret[k].shape[1:])\n",
    "        all_ret[k] = torch.reshape(all_ret[k], k_sh)\n",
    "\n",
    "    k_extract = ['rgb_map', 'disp_map', 'acc_map']\n",
    "    ret_list = [all_ret[k] for k in k_extract]\n",
    "    ret_dict = {k : all_ret[k] for k in all_ret if k not in k_extract}\n",
    "    return ret_list + [ret_dict]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e454bb41-775d-4a8e-8148-827453e2469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rays(H, W, K, c2w):\n",
    "    i, j = torch.meshgrid(torch.linspace(0, W-1, W), torch.linspace(0, H-1, H))  # pytorch's meshgrid has indexing='ij'\n",
    "    i = i.t()\n",
    "    j = j.t()\n",
    "    dirs = torch.stack([(i-K[0][2])/K[0][0], -(j-K[1][2])/K[1][1], -torch.ones_like(i)], -1)\n",
    "    # Rotate ray directions from camera frame to the world frame\n",
    "    rays_d = torch.sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1)  # dot product, equals to: [c2w.dot(dir) for dir in dirs]\n",
    "    # Translate camera frame's origin to the world frame. It is the origin of all rays.\n",
    "    rays_o = c2w[:3,-1].expand(rays_d.shape)\n",
    "    return rays_o, rays_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba9f2780-00db-4f16-84fe-b49ecdc8e8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify_rays(rays_flat, chunk=1024*32, **kwargs):\n",
    "    \"\"\"Render rays in smaller minibatches to avoid OOM.\n",
    "    \"\"\"\n",
    "    all_ret = {}\n",
    "    for i in range(0, rays_flat.shape[0], chunk):\n",
    "        ret = render_rays(rays_flat[i:i+chunk], **kwargs)\n",
    "        for k in ret:\n",
    "            if k not in all_ret:\n",
    "                all_ret[k] = []\n",
    "            all_ret[k].append(ret[k])\n",
    "\n",
    "    all_ret = {k : torch.cat(all_ret[k], 0) for k in all_ret}\n",
    "    return all_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "735de496-a4ed-4aa8-bbd9-219a3efa648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_rays(ray_batch,\n",
    "                network_fn,\n",
    "                network_query_fn,\n",
    "                N_samples,\n",
    "                retraw=False,\n",
    "                lindisp=False,\n",
    "                perturb=0.,\n",
    "                white_bkgd=False,\n",
    "                raw_noise_std=0.,\n",
    "                verbose=False):\n",
    "    N_rays = ray_batch.shape[0]\n",
    "    rays_o, rays_d = ray_batch[:,0:3], ray_batch[:,3:6]\n",
    "    bounds = torch.reshape(ray_batch[...,6:8], [-1,1,2])\n",
    "    near, far = bounds[...,0], bounds[...,1] # [-1,1]\n",
    "    viewdirs = ray_batch[:,8:11]\n",
    "    \n",
    "    t_vals = torch.linspace(0., 1., steps=N_samples)\n",
    "    if not lindisp:\n",
    "        z_vals = near * (1.-t_vals) + far * (t_vals)\n",
    "    else:\n",
    "        z_vals = 1./(1./near * (1.-t_vals) + 1./far * (t_vals))\n",
    "    z_vals = z_vals.expand([N_rays, N_samples])\n",
    "    \n",
    "    if perturb > 0.:\n",
    "        # get intervals between samples\n",
    "        mids = .5 * (z_vals[...,1:] + z_vals[...,:-1])\n",
    "        upper = torch.cat([mids, z_vals[...,-1:]], -1)\n",
    "        lower = torch.cat([z_vals[...,:1], mids], -1)\n",
    "        # stratified samples in those intervals\n",
    "        t_rand = torch.rand(z_vals.shape)\n",
    "        \n",
    "        z_vals = lower + (upper - lower) * t_rand\n",
    "    \n",
    "    pos = rays_o[...,None,:] + rays_d[...,None,:] * z_vals[...,:,None]\n",
    "    \n",
    "    raw = network_query_fn(pos, viewdirs, network_fn)\n",
    "    rgb_map, disp_map, acc_map, weights, depth_map = raw2outputs(raw, z_vals, rays_d, raw_noise_std, white_bkgd)\n",
    "    \n",
    "    ret = {'rgb_map' : rgb_map, 'disp_map' : disp_map, 'acc_map' : acc_map}\n",
    "    if retraw:\n",
    "        ret['raw'] = raw\n",
    "    \n",
    "    for k in ret:\n",
    "        if (torch.isnan(ret[k]).any() or torch.isinf(ret[k]).any()):\n",
    "            print(f\"! [Numerical Error] {k} contains nan or inf.\")\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdf61b00-1fa8-4360-ab2b-9a73c4954d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw2outputs(raw, z_vals, rays_d, raw_noise_std=0, white_bkgd=False):\n",
    "    \n",
    "    raw2alpha = lambda raw, dists, act_fn=F.relu: 1.-torch.exp(-act_fn(raw)*dists)\n",
    "    \n",
    "    dists = z_vals[...,1:] - z_vals[...,:-1]\n",
    "    dists = torch.cat([dists, torch.Tensor([1e10]).expand(dists[...,:1].shape)], -1)\n",
    "    \n",
    "    dists = dists * torch.norm(rays_d[...,None,:], dim=-1)\n",
    "    \n",
    "    rgb = raw[...,:3]\n",
    "    noise = 0.\n",
    "    if raw_noise_std > 0.:\n",
    "        noise = torch.randn(raw[...,3].shape) * raw_noise_std\n",
    "    \n",
    "    alpha = raw2alpha(raw[...,3] + noise, dists)\n",
    "    weights = alpha * torch.cumprod(torch.cat([torch.ones((alpha.shape[0], 1)), 1.-alpha + 1e-10], -1), -1)[:, :-1]\n",
    "    rgb_map = torch.sum(weights[...,None] * rgb, -2)\n",
    "    \n",
    "    depth_map = torch.sum(weights * z_vals, -1)\n",
    "    disp_map = 1./torch.max(1e-10 * torch.ones_like(depth_map), depth_map / torch.sum(weights, -1))\n",
    "    acc_map = torch.sum(weights, -1)\n",
    "\n",
    "    if white_bkgd:\n",
    "        rgb_map = rgb_map + (1.-acc_map[...,None])\n",
    "\n",
    "    return rgb_map, disp_map, acc_map, weights, depth_map    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e40128-2e58-44d8-bded-1fc5afec05f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Batchify Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c570d61-cd30-4441-ba9c-84a3583bc49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(fn, chunk):\n",
    "    \"\"\"Constructs a version of 'fn' that applies to smaller batches.\n",
    "    \"\"\"\n",
    "    if chunk is None:\n",
    "        return fn\n",
    "    def ret(inputs):\n",
    "        return torch.cat([fn(inputs[i:i+chunk]) for i in range(0, inputs.shape[0], chunk)], 0)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def run_network(inputs, viewdirs, fn, netchunk=1024*64):\n",
    "    \"\"\"Prepares inputs and applies network 'fn'.\n",
    "    \"\"\"\n",
    "    inputs_flat = torch.reshape(inputs, [-1, inputs.shape[-1]])\n",
    "    input_dirs = viewdirs[:,None].expand(inputs.shape)\n",
    "    input_dirs_flat = torch.reshape(input_dirs, [-1, input_dirs.shape[-1]])\n",
    "    \n",
    "    out = torch.cat([inputs_flat, input_dirs_flat], -1)\n",
    "     \n",
    "    outputs_flat = batchify(fn, netchunk)(out)\n",
    "\n",
    "    outputs = torch.reshape(outputs_flat, list(inputs.shape[:-1]) + [outputs_flat.shape[-1]])\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6deb7b-c7c9-4639-a2fe-479b47856730",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bb340bb-ee00-4b8c-928a-d7f2d25d6f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_pos = 3\n",
    "in_view = 3\n",
    "hidden = args.netwidth\n",
    "model = NeRF(in_pos, in_view, hidden)\n",
    "grad_vars = list(model.parameters())\n",
    "\n",
    "network_query_fn = lambda inputs, viewdirs, network_fn : run_network(inputs, viewdirs, network_fn,\n",
    "                                                                     netchunk=args.netchunk)\n",
    "optimizer = torch.optim.Adam(params=grad_vars, lr=args.lrate, betas=(0.9, 0.999))\n",
    "\n",
    "start = 0\n",
    "basedir = args.basedir\n",
    "expname = args.expname\n",
    "\n",
    "render_kwargs_train = {\n",
    "        'network_query_fn' : network_query_fn,\n",
    "        'perturb' : args.perturb,\n",
    "        'N_samples' : args.N_samples,\n",
    "        'network_fn' : model,\n",
    "        'white_bkgd' : args.white_bkgd,\n",
    "        'raw_noise_std' : args.raw_noise_std,\n",
    "    }\n",
    "\n",
    "if args.dataset_type != 'llff' or args.no_ndc:\n",
    "    print('Not ndc!')\n",
    "    render_kwargs_train['ndc'] = False\n",
    "    render_kwargs_train['lindisp'] = args.lindisp\n",
    "    \n",
    "render_kwargs_test = {k : render_kwargs_train[k] for k in render_kwargs_train}\n",
    "render_kwargs_test['perturb'] = False\n",
    "render_kwargs_test['raw_noise_std'] = 0.\n",
    "\n",
    "global_step = start\n",
    "bds_dict = {\n",
    "    'near' : near,\n",
    "    'far' : far,\n",
    "}\n",
    "render_kwargs_train.update(bds_dict)\n",
    "render_kwargs_test.update(bds_dict)\n",
    "\n",
    "render_poses = torch.Tensor(render_poses).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711cae83-cffe-4a5d-9d8f-e5592baf695f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0988fe67-89d5-4f29-9264-6fadea5865e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin\n",
      "TRAIN views are [ 1  2  3  4  5  6  7  9 10 11 12 13 14 15 17 18 19]\n",
      "TEST views are [ 0  8 16]\n",
      "VAL views are [ 0  8 16]\n"
     ]
    }
   ],
   "source": [
    "N_iters = 100000 + 1\n",
    "print('Begin')\n",
    "print('TRAIN views are', i_train)\n",
    "print('TEST views are', i_test)\n",
    "print('VAL views are', i_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7d3371d-3382-400b-a9c0-98d1f636b8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                                                                      | 101/100000 [00:10<2:17:36, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 100 Loss: 0.03330076485872269  PSNR: 14.775458335876465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                                                                      | 201/100000 [00:20<2:34:06, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 200 Loss: 0.027960598468780518  PSNR: 15.534534454345703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▌                                                                                                                                                                      | 302/100000 [00:31<2:19:41, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 300 Loss: 0.02517564967274666  PSNR: 15.990192413330078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▋                                                                                                                                                                      | 401/100000 [00:41<2:23:24, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 400 Loss: 0.02228948101401329  PSNR: 16.518999099731445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                                                                                                                      | 501/100000 [00:51<2:17:59, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 500 Loss: 0.025650298222899437  PSNR: 15.909074783325195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                                                                                                      | 601/100000 [01:01<2:18:27, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 600 Loss: 0.022476783022284508  PSNR: 16.48265838623047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                                                                                                     | 701/100000 [01:10<2:41:55, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 700 Loss: 0.02206098660826683  PSNR: 16.563751220703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                                                                                                     | 800/100000 [01:21<2:41:47, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 800 Loss: 0.019963767379522324  PSNR: 16.997573852539062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▍                                                                                                                                                                     | 833/100000 [01:24<2:47:56,  9.84it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18788\\1838575030.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mrays_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrays_rgb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrand_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mi_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     rgb, disp, acc, extras = render(H, W, K, chunk=args.chunk, rays=batch_rays,\n\u001b[0m\u001b[0;32m     15\u001b[0m                                                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretraw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                                                 **render_kwargs_train)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18788\\2388581145.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(H, W, K, chunk, rays, c2w, ndc, near, far, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mviewdirs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mall_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatchify_rays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_ret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mk_sh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_ret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18788\\2664115021.py\u001b[0m in \u001b[0;36mbatchify_rays\u001b[1;34m(rays_flat, chunk, **kwargs)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mall_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrays_flat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrender_rays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrays_flat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_ret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18788\\1738846428.py\u001b[0m in \u001b[0;36mrender_rays\u001b[1;34m(ray_batch, network_fn, network_query_fn, N_samples, retraw, lindisp, perturb, white_bkgd, raw_noise_std, verbose)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrays_o\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrays_d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mz_vals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork_query_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mviewdirs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mrgb_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisp_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw2outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrays_d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_noise_std\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhite_bkgd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18788\\133564906.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(inputs, viewdirs, network_fn)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgrad_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m network_query_fn = lambda inputs, viewdirs, network_fn : run_network(inputs, viewdirs, network_fn,\n\u001b[0m\u001b[0;32m      8\u001b[0m                                                                      netchunk=args.netchunk)\n\u001b[0;32m      9\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.999\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18788\\3127815879.py\u001b[0m in \u001b[0;36mrun_network\u001b[1;34m(inputs, viewdirs, fn, netchunk)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs_flat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dirs_flat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0moutputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatchify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs_flat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0moutputs_flat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18788\\3127815879.py\u001b[0m in \u001b[0;36mret\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18788\\3127815879.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18788\\3575492603.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_view\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0moffset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnerf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18788\\3575492603.py\u001b[0m in \u001b[0;36mnerf\u001b[1;34m(self, pos, view)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = start + 1\n",
    "for i in trange(start, N_iters):\n",
    "    time0 = time.time()\n",
    "    batch = rays_rgb[i_batch:i_batch+N_rand]\n",
    "    batch = torch.transpose(batch, 0, 1)\n",
    "    batch_rays, target_s = batch[:2], batch[2]\n",
    "    \n",
    "    i_batch += N_rand\n",
    "    if i_batch >= rays_rgb.shape[0]:\n",
    "        print(\"Shuffle data after an epoch!\")\n",
    "        rand_idx = torch.randperm(rays_rgb.shape[0])\n",
    "        rays_rgb = rays_rgb[rand_idx]\n",
    "        i_batch = 0\n",
    "    rgb, disp, acc, extras = render(H, W, K, chunk=args.chunk, rays=batch_rays,\n",
    "                                                verbose=i < 10, retraw=True,\n",
    "                                                **render_kwargs_train)\n",
    "    optimizer.zero_grad()\n",
    "    img_loss = img2mse(rgb, target_s)\n",
    "    loss = img_loss\n",
    "    psnr = mse2psnr(img_loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    decay_rate = 0.1\n",
    "    decay_steps = args.lrate_decay * 1000\n",
    "    new_lrate = args.lrate * (decay_rate ** (global_step / decay_steps))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = new_lrate\n",
    "        \n",
    "    if i%args.i_print==0:\n",
    "        tqdm.write(f\"[TRAIN] Iter: {i} Loss: {loss.item()}  PSNR: {psnr.item()}\")\n",
    "            \n",
    "    if i%args.i_video==0 and i > 0:\n",
    "        # Turn on testing mode\n",
    "        with torch.no_grad():\n",
    "            rgbs, disps = render_path(render_poses, hwf, K, args.chunk, render_kwargs_test)\n",
    "        print('Done, saving', rgbs.shape, disps.shape)\n",
    "        moviebase = os.path.join(basedir, expname, '{}_spiral_{:06d}_'.format(expname, i))\n",
    "        imageio.mimwrite(moviebase + 'rgb.mp4', to8b(rgbs), fps=30, quality=8)\n",
    "        imageio.mimwrite(moviebase + 'disp.mp4', to8b(disps / np.max(disps)), fps=30, quality=8)\n",
    "\n",
    "            # if args.use_viewdirs:\n",
    "            #     render_kwargs_test['c2w_staticcam'] = render_poses[0][:3,:4]\n",
    "            #     with torch.no_grad():\n",
    "            #         rgbs_still, _ = render_path(render_poses, hwf, args.chunk, render_kwargs_test)\n",
    "            #     render_kwargs_test['c2w_staticcam'] = None\n",
    "            #     imageio.mimwrite(moviebase + 'rgb_still.mp4', to8b(rgbs_still), fps=30, quality=8)\n",
    "\n",
    "    if i%args.i_testset==0 and i > 0:\n",
    "        testsavedir = os.path.join(basedir, expname, 'testset_{:06d}'.format(i))\n",
    "        os.makedirs(testsavedir, exist_ok=True)\n",
    "        print('test poses shape', poses[i_test].shape)\n",
    "        with torch.no_grad():\n",
    "            render_path(torch.Tensor(poses[i_test]).to(device), hwf, K, args.chunk, render_kwargs_test, gt_imgs=images[i_test], savedir=testsavedir)\n",
    "        print('Saved test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7d544-b43f-4849-adcd-7c6aa9d5efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_path(render_poses, hwf, K, chunk, render_kwargs, gt_imgs=None, savedir=None, render_factor=0):\n",
    "\n",
    "    H, W, focal = hwf\n",
    "\n",
    "    if render_factor!=0:\n",
    "        # Render downsampled for speed\n",
    "        H = H//render_factor\n",
    "        W = W//render_factor\n",
    "        focal = focal/render_factor\n",
    "\n",
    "    rgbs = []\n",
    "    disps = []\n",
    "\n",
    "    t = time.time()\n",
    "    for i, c2w in enumerate(tqdm(render_poses)):\n",
    "        print(i, time.time() - t)\n",
    "        t = time.time()\n",
    "        rgb, disp, acc, _ = render(H, W, K, chunk=chunk, c2w=c2w[:3,:4], **render_kwargs)\n",
    "        rgbs.append(rgb.cpu().numpy())\n",
    "        disps.append(disp.cpu().numpy())\n",
    "        if i==0:\n",
    "            print(rgb.shape, disp.shape)\n",
    "\n",
    "        \"\"\"\n",
    "        if gt_imgs is not None and render_factor==0:\n",
    "            p = -10. * np.log10(np.mean(np.square(rgb.cpu().numpy() - gt_imgs[i])))\n",
    "            print(p)\n",
    "        \"\"\"\n",
    "\n",
    "        if savedir is not None:\n",
    "            rgb8 = to8b(rgbs[-1])\n",
    "            filename = os.path.join(savedir, '{:03d}.png'.format(i))\n",
    "            imageio.imwrite(filename, rgb8)\n",
    "\n",
    "\n",
    "    rgbs = np.stack(rgbs, 0)\n",
    "    disps = np.stack(disps, 0)\n",
    "\n",
    "    return rgbs, disps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf9c43-2221-4525-aafe-e9b27f83c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    rgbs, disps = render_path(render_poses, hwf, K, args.chunk, render_kwargs_test)\n",
    "    print('Done, saving', rgbs.shape, disps.shape)\n",
    "    moviebase = os.path.join(basedir, expname, '{}_spiral_{:06d}_'.format(expname, i))\n",
    "    imageio.mimwrite(moviebase + 'rgb.mp4', to8b(rgbs), fps=30, quality=8)\n",
    "    imageio.mimwrite(moviebase + 'disp.mp4', to8b(disps / np.max(disps)), fps=30, quality=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7f537-6e13-453c-bead-69cb05f0af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsavedir = os.path.join(basedir, expname, 'testset_{:06d}'.format(i))\n",
    "os.makedirs(testsavedir, exist_ok=True)\n",
    "print('test poses shape', poses[i_test].shape)\n",
    "with torch.no_grad():\n",
    "    render_path(torch.Tensor(poses[i_test]).to(device), hwf, K, args.chunk, render_kwargs_test, gt_imgs=images[i_test], savedir=testsavedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb82670-90cb-4d8b-800d-65abde3eeb55",
   "metadata": {},
   "source": [
    "## Various Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dbfc5c-27a3-4445-8896-cf74df52a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = rays_rgb[i_batch:i_batch+N_rand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec5bf9-bd88-41b2-aa7e-8bac6cd1c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.transpose(batch, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca62fd-4195-4462-970f-ae9b409b8230",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aeb227-8787-4ba3-9fb1-f749fb1de68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_rays, target_s = batch[:2], batch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e273ca96-dae6-41d8-8625-a84b5b6aaa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_batch += N_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fed3c16-ad84-4e08-af6a-fd8328bfd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_rays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975b904-c342-4cc4-963f-0c0e4a3678b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk=args.chunk\n",
    "rays=batch_rays\n",
    "verbose=True\n",
    "retraw=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6eb6f1-ab29-46d1-a13a-d7b032631bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rays_o, rays_d = rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dace8bd-c16e-4a2e-8bde-ad198b570ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = rays_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c129d-e0c7-4208-9e00-c7198eca9169",
   "metadata": {},
   "outputs": [],
   "source": [
    "sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864ed0c3-ff8b-4938-a0de-35fb74513e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "rays_o, rays_d = ndc_rays(H, W, K[0][0], 1., rays_o, rays_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b65eed-991a-4b00-a386-7ad3685908fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rays_o = torch.reshape(rays_o, [-1,3]).float()\n",
    "rays_d = torch.reshape(rays_d, [-1,3]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be58e98f-fc35-44ee-af8b-48ba52c5547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rays_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba26cf8-3d00-4665-af90-df8ecf851057",
   "metadata": {},
   "outputs": [],
   "source": [
    "near, far = near * torch.ones_like(rays_d[...,:1]), far * torch.ones_like(rays_d[...,:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111caea9-6ad7-4822-9eab-a9425e14eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rays = torch.cat([rays_o, rays_d, near, far], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c236566b-291f-4646-83fd-b4146cb01d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_batch = rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd6b9d7-05b1-495e-b8ed-46bb070b8397",
   "metadata": {},
   "outputs": [],
   "source": [
    "rays[:,-3:].shaperays_o, rays_d = ray_batch[:,0:3], ray_batch[:,3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3aaac8-b8d9-4ea8-9ae4-7318a5acd62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_batch[:,3:6]-rays_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44f67eb-b084-4471-b047-af6693c3671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = torch.reshape(ray_batch[...,6:8], [-1,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f01124-359a-4043-b00a-6d54e21750ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a631a05c-9084-4e9b-afe0-d91ce89a0b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.use_viewdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec16fdf-1fb1-493c-a076-2146806c89bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewdirs = rays_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9244f80-9496-48f0-9592-b8d0dc14b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewdirs = viewdirs / torch.norm(viewdirs, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f905e9-34e4-4d6f-9567-d3606d36268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewdirs = torch.reshape(viewdirs, [-1,3]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1409c7bf-1a37-4603-9e16-cc80bbd0aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb78600-d91d-4567-81b9-ff1debfdb38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rays_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed248d8-b8ff-476c-b984-f4a23af89945",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeRF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f894195-7a6e-4cd3-a102-f9b5b39f4c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(rays_o,viewdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a33e510-52a2-47e4-8b4d-279a1cf1fb85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
