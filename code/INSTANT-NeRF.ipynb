{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8096bd69-06cb-45ba-947b-9256fc000e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import imageio\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import commentjson as json\n",
    "import tinycudann as tcnn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "997f21e3-98fa-4606-99f9-3c6cba80f83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_llff import load_llff_data\n",
    "from load_deepvoxels import load_dv_data\n",
    "from load_blender import load_blender_data\n",
    "from load_LINEMOD import load_LINEMOD_data\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b186f6-12f6-4b15-ae60-61a66d731af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "np.random.seed(0)\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c1e80f-d942-48c1-9df5-3bc1b1d9d0f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0efb0e76-9a75-438b-bc6e-104cacef9cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = config_parser()\n",
    "args = parser.parse_args('--config C:/Users/chuzh/Study/CIS565/final/Neural-Radiance-Fields-with-Refractions/code/configs/lego.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f32c13a-768b-4228-843f-ed2ffc7360d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.nnconfig) as config_file:\n",
    "    nnconfig = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb528a90-b17b-49a8-a355-dded4ed64c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded blender (138, 800, 800, 4) torch.Size([40, 4, 4]) [800, 800, 1111.1110311937682] ./data/nerf_synthetic/lego\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "K = None\n",
    "if args.dataset_type == 'llff':\n",
    "    images, poses, bds, render_poses, i_test = load_llff_data(args.datadir, args.factor,\n",
    "                                                                  recenter=True, bd_factor=.75,\n",
    "                                                                  spherify=args.spherify)\n",
    "    hwf = poses[0,:3,-1]\n",
    "    poses = poses[:,:3,:4]\n",
    "    print('Loaded llff', images.shape, render_poses.shape, hwf, args.datadir)\n",
    "    if not isinstance(i_test, list):\n",
    "        i_test = [i_test]\n",
    "\n",
    "    if args.llffhold > 0:\n",
    "        print('Auto LLFF holdout,', args.llffhold)\n",
    "        i_test = np.arange(images.shape[0])[::args.llffhold]\n",
    "\n",
    "    i_val = i_test\n",
    "    i_train = np.array([i for i in np.arange(int(images.shape[0])) if\n",
    "                        (i not in i_test and i not in i_val)])\n",
    "\n",
    "    print('DEFINING BOUNDS')\n",
    "    if args.no_ndc:\n",
    "        near = np.ndarray.min(bds) * .9\n",
    "        far = np.ndarray.max(bds) * 1.\n",
    "            \n",
    "    else:\n",
    "        near = 0.\n",
    "        far = 1.\n",
    "    print('NEAR FAR', near, far)\n",
    "\n",
    "elif args.dataset_type == 'blender':\n",
    "    images, poses, render_poses, hwf, i_split = load_blender_data(args.datadir, args.half_res, args.testskip)\n",
    "    print('Loaded blender', images.shape, render_poses.shape, hwf, args.datadir)\n",
    "    i_train, i_val, i_test = i_split\n",
    "\n",
    "    near = 2.\n",
    "    far = 6.\n",
    "\n",
    "    if args.white_bkgd:\n",
    "        images = images[...,:3]*images[...,-1:] + (1.-images[...,-1:])\n",
    "    else:\n",
    "        images = images[...,:3]\n",
    "\n",
    "elif args.dataset_type == 'LINEMOD':\n",
    "    images, poses, render_poses, hwf, K, i_split, near, far = load_LINEMOD_data(args.datadir, args.half_res, args.testskip)\n",
    "    print(f'Loaded LINEMOD, images shape: {images.shape}, hwf: {hwf}, K: {K}')\n",
    "    print(f'[CHECK HERE] near: {near}, far: {far}.')\n",
    "    i_train, i_val, i_test = i_split\n",
    "\n",
    "    if args.white_bkgd:\n",
    "        images = images[...,:3]*images[...,-1:] + (1.-images[...,-1:])\n",
    "    else:\n",
    "        images = images[...,:3]\n",
    "\n",
    "elif args.dataset_type == 'deepvoxels':\n",
    "\n",
    "    images, poses, render_poses, hwf, i_split = load_dv_data(scene=args.shape,\n",
    "                                                                 basedir=args.datadir,\n",
    "                                                                 testskip=args.testskip)\n",
    "\n",
    "    print('Loaded deepvoxels', images.shape, render_poses.shape, hwf, args.datadir)\n",
    "    i_train, i_val, i_test = i_split\n",
    "\n",
    "    hemi_R = np.mean(np.linalg.norm(poses[:,:3,-1], axis=-1))\n",
    "    near = hemi_R-1.\n",
    "    far = hemi_R+1.\n",
    "\n",
    "else:\n",
    "    print('Unknown dataset type', args.dataset_type, 'exiting')\n",
    "\n",
    "# Cast intrinsics to right types\n",
    "H, W, focal = hwf\n",
    "H, W = int(H), int(W)\n",
    "hwf = [H, W, focal]\n",
    "\n",
    "if K is None:\n",
    "    K = np.array([\n",
    "        [focal, 0, 0.5*W],\n",
    "        [0, focal, 0.5*H],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "if args.render_test:\n",
    "    render_poses = np.array(poses[i_test])\n",
    "\n",
    "# Create log dir and copy the config file\n",
    "basedir = args.basedir\n",
    "expname = args.expname\n",
    "os.makedirs(os.path.join(basedir, expname), exist_ok=True)\n",
    "f = os.path.join(basedir, expname, 'args.txt')\n",
    "with open(f, 'w') as file:\n",
    "    for arg in sorted(vars(args)):\n",
    "        attr = getattr(args, arg)\n",
    "        file.write('{} = {}\\n'.format(arg, attr))\n",
    "if args.config is not None:\n",
    "    f = os.path.join(basedir, expname, 'config.txt')\n",
    "    with open(f, 'w') as file:\n",
    "        file.write(open(args.config, 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af6309-5650-43be-8acd-ae85715e0882",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a996f3-9fbf-4fa6-b04f-07483c338697",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_rand = args.N_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b5f3d27-f322-45fe-9330-107897cf0953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get rays\n",
      "done, concats\n",
      "shuffle rays\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('get rays')\n",
    "rays = np.stack([get_rays_np(H, W, K, p) for p in poses[:,:3,:4]], 0) # [N, ro+rd, H, W, 3]\n",
    "print('done, concats')\n",
    "rays_rgb = np.concatenate([rays, images[:,None]], 1) # [N, ro+rd+rgb, H, W, 3]\n",
    "rays_rgb = np.transpose(rays_rgb, [0,2,3,1,4]) # [N, H, W, ro+rd+rgb, 3]\n",
    "rays_rgb = np.stack([rays_rgb[i] for i in i_train], 0) # train images only\n",
    "rays_rgb = np.reshape(rays_rgb, [-1,3,3]) # [(N-1)*H*W, ro+rd+rgb, 3]\n",
    "rays_rgb = rays_rgb.astype(np.float32)\n",
    "print('shuffle rays')\n",
    "np.random.shuffle(rays_rgb)\n",
    "\n",
    "print('done')\n",
    "i_batch = 0\n",
    "\n",
    "images = torch.Tensor(images).to(device)\n",
    "poses = torch.Tensor(poses).to(device)\n",
    "rays_rgb = torch.Tensor(rays_rgb).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4579e44d-b387-403d-941b-4cb800c5e66c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a117b51-1c75-4c58-8cb2-fddfa4e36961",
   "metadata": {},
   "outputs": [],
   "source": [
    "class instant_NeRF(nn.Module):\n",
    "    def __init__(self, pos_in = 3, dir_in = 3, pos_out = 16, nnconfig = None):\n",
    "        super(instant_NeRF, self).__init__()\n",
    "        self.pos_in, self.dir_in = pos_in, dir_in\n",
    "        self.pos_encoding = tcnn.Encoding(pos_in , nnconfig[\"encoding\"])\n",
    "        self.density = tcnn.Network(n_input_dims=self.pos_encoding.n_output_dims, n_output_dims=16, network_config=nnconfig[\"network\"])\n",
    "        self.dir_encoding = tcnn.Encoding(dir_in, nnconfig[\"dir_encoding\"])\n",
    "        self.rgb = tcnn.Network(n_input_dims=self.dir_encoding.n_output_dims + pos_out, n_output_dims=3, network_config=nnconfig[\"rgb_network\"])\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pos, view = torch.split(x, [self.pos_in, self.dir_in], dim=-1)\n",
    "        encoded_pos = self.pos_encoding(pos)\n",
    "        encoded_dir = self.dir_encoding(view)\n",
    "        density = self.density(encoded_pos)\n",
    "        rgb = self.rgb(torch.cat([density, encoded_dir], -1))\n",
    "        \n",
    "        return torch.cat([rgb,density[...,:1]], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6deb7b-c7c9-4639-a2fe-479b47856730",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0551de9e-d9a4-41d0-9702-4d0db9aded5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not ndc!\n"
     ]
    }
   ],
   "source": [
    "in_pos = 3\n",
    "in_view = 3\n",
    "model = instant_NeRF(pos_in = in_pos, dir_in = in_view, nnconfig = nnconfig)\n",
    "grad_vars = list(model.parameters())\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "{'params':[grad_vars[0]],'weight_decay': 0},\n",
    "{'params':grad_vars[1:],'weight_decay': 1e-6}\n",
    "], lr=1e-2, betas=(0.9, 0.99), eps = 1e-15)\n",
    "\n",
    "start = 0\n",
    "basedir = args.basedir\n",
    "expname = args.expname\n",
    "\n",
    "render_kwargs_train = {\n",
    "        'perturb' : args.perturb,\n",
    "        'N_samples' : args.N_samples,\n",
    "        'network' : model,\n",
    "        'white_bkgd' : args.white_bkgd,\n",
    "        'raw_noise_std' : args.raw_noise_std,\n",
    "    }\n",
    "\n",
    "if args.dataset_type != 'llff' or args.no_ndc:\n",
    "    print('Not ndc!')\n",
    "    render_kwargs_train['ndc'] = False\n",
    "    render_kwargs_train['lindisp'] = args.lindisp\n",
    "    \n",
    "render_kwargs_test = {k : render_kwargs_train[k] for k in render_kwargs_train}\n",
    "render_kwargs_test['perturb'] = False\n",
    "render_kwargs_test['raw_noise_std'] = 0.\n",
    "\n",
    "global_step = start\n",
    "bds_dict = {\n",
    "    'near' : near,\n",
    "    'far' : far,\n",
    "}\n",
    "render_kwargs_train.update(bds_dict)\n",
    "render_kwargs_test.update(bds_dict)\n",
    "\n",
    "render_poses = torch.Tensor(render_poses).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9a903-39a1-4b58-a510-72d5c45cc9f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Render Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c75ff21-5175-445d-a789-2e2b2b34f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(H, W, K, rays = None, ndc = True, near = 0., far = 1.,\n",
    "           N_samples = 0,\n",
    "           network = None,\n",
    "           retraw=False,\n",
    "           lindisp=False,\n",
    "           perturb=0.,\n",
    "           white_bkgd=False,\n",
    "           raw_noise_std=0.,\n",
    "           verbose=False):\n",
    "\n",
    "    rays_o, rays_d = rays\n",
    "        \n",
    "    viewdirs = rays_d\n",
    "    viewdirs = viewdirs / torch.norm(viewdirs, dim=-1, keepdim=True)\n",
    "    viewdirs = torch.reshape(viewdirs, [-1,3]).float()\n",
    "    \n",
    "    shape = rays_d.shape\n",
    "    if ndc:\n",
    "        rays_o, rays_d = ndc_rays(H, W, K[0][0], 1., rays_o, rays_d)\n",
    "        \n",
    "    rays_o = torch.reshape(rays_o, [-1,3]).float()\n",
    "    rays_d = torch.reshape(rays_d, [-1,3]).float()\n",
    "    near, far = near * torch.ones_like(rays_d[...,:1]), far * torch.ones_like(rays_d[...,:1])\n",
    "    \n",
    "    N_rays = rays_o.shape[0]\n",
    "    \n",
    "    t_vals = torch.linspace(0., 1., steps=N_samples)\n",
    "    if not lindisp:\n",
    "        z_vals = near * (1.-t_vals) + far * (t_vals)\n",
    "    else:\n",
    "        z_vals = 1./(1./near * (1.-t_vals[:-1]) + 1./far * (t_vals[:-1]))\n",
    "    z_vals = z_vals.expand([N_rays, N_samples])\n",
    "    \n",
    "    if perturb > 0.:\n",
    "        # get intervals between samples\n",
    "        mids = .5 * (z_vals[...,1:] + z_vals[...,:-1])\n",
    "        upper = torch.cat([mids, z_vals[...,-1:]], -1)\n",
    "        lower = torch.cat([z_vals[...,:1], mids], -1)\n",
    "        # stratified samples in those intervals\n",
    "        t_rand = torch.rand(z_vals.shape)\n",
    "        \n",
    "        z_vals = lower + (upper - lower) * t_rand\n",
    "        \n",
    "    pos = rays_o[...,None,:] + rays_d[...,None,:] * z_vals[...,:,None]\n",
    "    pos_flat = torch.reshape(pos, [-1, pos.shape[-1]])\n",
    "    \n",
    "    dirs = viewdirs[:,None].expand(pos.shape)\n",
    "    dirs_flat = torch.reshape(dirs, [-1, dirs.shape[-1]])\n",
    "    \n",
    "    inputs = torch.cat([pos_flat, dirs_flat], -1)\n",
    "     \n",
    "    rgbs = network(inputs)\n",
    "\n",
    "    rgbs = torch.reshape(rgbs, list(pos.shape[:-1]) + [rgbs.shape[-1]])\n",
    "    \n",
    "    rgbs2alpha = lambda rgbs, dists, act_fn=F.relu: 1.-torch.exp(-act_fn(rgbs)*dists)\n",
    "    \n",
    "    dists = z_vals[...,1:] - z_vals[...,:-1]\n",
    "    dists = torch.cat([dists, torch.Tensor([1e10]).expand(dists[...,:1].shape)], -1)\n",
    "    \n",
    "    dists = dists * torch.norm(rays_d[...,None,:], dim=-1)\n",
    "    rgb = torch.sigmoid(rgbs[...,:3])\n",
    "    \n",
    "    noise = 0.\n",
    "    if raw_noise_std > 0.:\n",
    "        noise = torch.randn(rgbs[...,3].shape) * raw_noise_std\n",
    "    \n",
    "    alpha = rgbs2alpha(rgbs[...,3] + noise, dists)\n",
    "    weights = alpha * torch.cumprod(torch.cat([torch.ones((alpha.shape[0], 1)), 1.-alpha + 1e-10], -1), -1)[:, :-1]\n",
    "    rgb_map = torch.sum(weights[...,None] * rgb, -2)\n",
    "    \n",
    "    depth_map = torch.sum(weights * z_vals, -1)\n",
    "    disp_map = 1./torch.max(1e-10 * torch.ones_like(depth_map), depth_map / torch.sum(weights, -1))\n",
    "    acc_map = torch.sum(weights, -1)\n",
    "\n",
    "    if white_bkgd:\n",
    "        rgb_map = rgb_map + (1.-acc_map[...,None])\n",
    "\n",
    "    others = {}\n",
    "    \n",
    "    return rgb_map, disp_map, acc_map, others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2c7d544-b43f-4849-adcd-7c6aa9d5efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_path(render_poses, hwf, K, render_kwargs, chunk = 1024, gt_imgs=None, savedir=None, render_factor=0):\n",
    "\n",
    "    H, W, focal = hwf\n",
    "\n",
    "    if render_factor!=0:\n",
    "        # Render downsampled for speed\n",
    "        H = H//render_factor\n",
    "        W = W//render_factor\n",
    "        focal = focal/render_factor\n",
    "\n",
    "    rgbs = []\n",
    "    disps = []\n",
    "    \n",
    "    total_time = 0\n",
    "\n",
    "    t = time.time()\n",
    "    for i, c2w in enumerate(render_poses):\n",
    "        t = time.time()\n",
    "        rays_o, rays_d = get_rays(H, W, K, c2w[:3,:4])\n",
    "        rays_o = rays_o.reshape(H * W, 3)\n",
    "        rays_d = rays_d.reshape(H * W, 3)\n",
    "        rgb = torch.zeros(H * W, 3)\n",
    "        disp = torch.zeros(H * W)\n",
    "        acc = torch.zeros(H * W)\n",
    "        for j in range(0, H * W, chunk):\n",
    "            rgb[j:j+chunk], disp[j:j+chunk], acc[j:j+chunk], _ = render(H, W, K, (rays_o[j:j+chunk], rays_d[j:j+chunk]), **render_kwargs)\n",
    "        disp = disp / disp.max()\n",
    "        rgbs.append(rgb.reshape(H, W, 3).cpu().numpy())\n",
    "        disps.append(disp.reshape(H, W).cpu().numpy())\n",
    "        \n",
    "        total_time += time.time() - t\n",
    "\n",
    "        \"\"\"\n",
    "        if gt_imgs is not None and render_factor==0:\n",
    "            p = -10. * np.log10(np.mean(np.square(rgb.cpu().numpy() - gt_imgs[i])))\n",
    "            print(p)\n",
    "        \"\"\"\n",
    "\n",
    "        if savedir is not None:\n",
    "            rgb8 = to8b(rgbs[-1])\n",
    "            filename = os.path.join(savedir, '{:03d}.png'.format(i))\n",
    "            imageio.imwrite(filename, rgb8)\n",
    "\n",
    "\n",
    "    rgbs = np.stack(rgbs, 0)\n",
    "    disps = np.stack(disps, 0)\n",
    "    \n",
    "    print('average render time:', total_time / len(render_poses))\n",
    "\n",
    "    return rgbs, disps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "522e8b6b-98db-419f-b24c-c9a7e4fd5b7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26100\\2207959393.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "inputs.shape[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711cae83-cffe-4a5d-9d8f-e5592baf695f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0988fe67-89d5-4f29-9264-6fadea5865e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin\n",
      "TRAIN views are [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99]\n",
      "TEST views are [113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130\n",
      " 131 132 133 134 135 136 137]\n",
      "VAL views are [100 101 102 103 104 105 106 107 108 109 110 111 112]\n"
     ]
    }
   ],
   "source": [
    "N_iters = 200000 + 1\n",
    "print('Begin')\n",
    "print('TRAIN views are', i_train)\n",
    "print('TEST views are', i_test)\n",
    "print('VAL views are', i_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7d3371d-3382-400b-a9c0-98d1f636b8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████████▍                                                                                                                                                               | 9991/200000 [01:56<36:57, 85.68it/s]C:\\Users\\chuzh\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 10000 Loss: 0.018529970198869705  PSNR: 17.321252822875977\n",
      "test poses shape torch.Size([25, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████████▏                                                                                                                                                           | 10009/200000 [02:45<60:30:09,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average render time: 1.412659034729004\n",
      "Saved test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████████████▋                                                                                                                                                      | 19996/200000 [04:43<36:18, 82.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 20000 Loss: 0.016631726175546646  PSNR: 17.790626525878906\n",
      "test poses shape torch.Size([25, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████████████▍                                                                                                                                                   | 20009/200000 [05:36<69:53:13,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average render time: 1.44331711769104\n",
      "Saved test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████████████████                                                                                                                                              | 29996/200000 [07:36<32:57, 85.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 30000 Loss: 0.011511610820889473  PSNR: 19.388639450073242\n",
      "test poses shape torch.Size([25, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████████████████▌                                                                                                                                           | 30018/200000 [08:26<42:36:12,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average render time: 1.4063135528564452\n",
      "Saved test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████████████████████▍                                                                                                                                     | 39997/200000 [10:24<32:40, 81.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 40000 Loss: 0.012791832908987999  PSNR: 18.93067169189453\n",
      "test poses shape torch.Size([25, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████████████████████▊                                                                                                                                   | 40018/200000 [11:13<39:59:49,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average render time: 1.4032281684875487\n",
      "Saved test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████████████████████████▋                                                                                                                             | 49997/200000 [13:11<29:31, 84.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 50000 Loss: 0.009811382740736008  PSNR: 20.082698822021484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████████████████████████▋                                                                                                                             | 49997/200000 [13:30<29:31, 84.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average render time: 1.4517602801322937\n",
      "Done, saving (40, 800, 800, 3) (40, 800, 800)\n",
      "test poses shape torch.Size([25, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████████████████████████▊                                                                                                                          | 50008/200000 [15:02<130:08:36,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average render time: 1.461791000366211\n",
      "Saved test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████████████████████████████                                                                                                                     | 59994/200000 [17:02<27:42, 84.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 60000 Loss: 0.010239677503705025  PSNR: 19.897138595581055\n",
      "test poses shape torch.Size([25, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████████████████████████████▏                                                                                                                  | 60009/200000 [17:52<49:11:35,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average render time: 1.4642861366271973\n",
      "Saved test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████████████████████████████████▍                                                                                                            | 69994/200000 [20:07<25:59, 83.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 70000 Loss: 0.010131310671567917  PSNR: 19.943344116210938\n",
      "test poses shape torch.Size([25, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████████████████████████████████▍                                                                                                          | 70008/200000 [20:57<47:58:09,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average render time: 1.4624547004699706\n",
      "Saved test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████████████████████████████▊                                                                                                    | 79992/200000 [23:08<24:22, 82.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 80000 Loss: 0.011115392670035362  PSNR: 19.54075050354004\n",
      "test poses shape torch.Size([25, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████████████████████████████████████▌                                                                                                  | 80008/200000 [24:02<46:31:57,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average render time: 1.6480175018310548\n",
      "Saved test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████████████████████████████████████████▏                                                                                           | 89991/200000 [26:23<21:24, 85.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 90000 Loss: 0.010407477617263794  PSNR: 19.82654571533203\n",
      "test poses shape torch.Size([25, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████████████████████████████████████████▊                                                                                          | 90018/200000 [27:13<25:31:15,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average render time: 1.4972771644592284\n",
      "Saved test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████████████████████████████████████████████▍                                                                                   | 99998/200000 [29:21<25:06, 66.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Iter: 100000 Loss: 0.009664545767009258  PSNR: 20.14818572998047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████████████████████████████████████████████▍                                                                                   | 99998/200000 [29:31<25:06, 66.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average render time: 1.5959432184696198\n",
      "Done, saving (40, 800, 800, 3) (40, 800, 800)\n",
      "test poses shape torch.Size([25, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████████████████████████████████████████████                                                                                 | 100008/200000 [31:20<106:44:38,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average render time: 1.6108227920532228\n",
      "Saved test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████████████████████████████████████████████████████████████▋                                                                           | 109199/200000 [33:38<27:58, 54.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26100\\3156027530.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mrays_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrays_rgb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrand_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mi_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     rgb, disp, acc, extras = render(H, W, K, rays=batch_rays,\n\u001b[0m\u001b[0;32m     15\u001b[0m                                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretraw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                                     **render_kwargs_train)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = start + 1\n",
    "for i in trange(start, N_iters):\n",
    "    time0 = time.time()\n",
    "    batch = rays_rgb[i_batch:i_batch+N_rand]\n",
    "    batch = torch.transpose(batch, 0, 1)\n",
    "    batch_rays, target_s = batch[:2], batch[2]\n",
    "    \n",
    "    i_batch += N_rand\n",
    "    if i_batch >= rays_rgb.shape[0]:\n",
    "        #print(\"Shuffle data after an epoch!\")\n",
    "        rand_idx = torch.randperm(rays_rgb.shape[0])\n",
    "        rays_rgb = rays_rgb[rand_idx]\n",
    "        i_batch = 0\n",
    "    rgb, disp, acc, extras = render(H, W, K, rays=batch_rays,\n",
    "                                    verbose=i < 10, retraw=True,\n",
    "                                    **render_kwargs_train)\n",
    "    optimizer.zero_grad()\n",
    "    img_loss = img2mse(rgb, target_s)\n",
    "    loss = img_loss\n",
    "    psnr = mse2psnr(img_loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    if (i >= 20000) and (i % 10000 == 0):\n",
    "        new_lrate = args.lrate * 0.33\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = new_lrate\n",
    "        \n",
    "    if i % args.i_print == 0:\n",
    "        tqdm.write(f\"[TRAIN] Iter: {i} Loss: {loss.item()}  PSNR: {psnr.item()}\")\n",
    "            \n",
    "    if (i % args.i_video == 0) and (i > 0):\n",
    "        # Turn on testing mode\n",
    "        with torch.no_grad():\n",
    "            rgbs, disps = render_path(render_poses, hwf, K, render_kwargs_test)\n",
    "        print('Done, saving', rgbs.shape, disps.shape)\n",
    "        moviebase = os.path.join(basedir, expname, '{}_spiral_{:06d}_'.format(expname, i))\n",
    "        imageio.mimwrite(moviebase + 'rgb.mp4', to8b(rgbs), fps=30, quality=8)\n",
    "        imageio.mimwrite(moviebase + 'disp.mp4', to8b(disps / np.max(disps)), fps=30, quality=8)\n",
    "\n",
    "            # if args.use_viewdirs:\n",
    "            #     render_kwargs_test['c2w_staticcam'] = render_poses[0][:3,:4]\n",
    "            #     with torch.no_grad():\n",
    "            #         rgbs_still, _ = render_path(render_poses, hwf, args.chunk, render_kwargs_test)\n",
    "            #     render_kwargs_test['c2w_staticcam'] = None\n",
    "            #     imageio.mimwrite(moviebase + 'rgb_still.mp4', to8b(rgbs_still), fps=30, quality=8)\n",
    "\n",
    "    if i%args.i_testset==0 and i > 0:\n",
    "        testsavedir = os.path.join(basedir, expname, 'testset_{:06d}'.format(i))\n",
    "        os.makedirs(testsavedir, exist_ok=True)\n",
    "        print('test poses shape', poses[i_test].shape)\n",
    "        with torch.no_grad():\n",
    "            render_path(torch.Tensor(poses[i_test]).to(device), hwf, K, render_kwargs_test, gt_imgs=images[i_test], savedir=testsavedir)\n",
    "        print('Saved test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd03cd5-ce57-4ad2-8057-a35c8acf46e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    rgbs, disps = render_path(render_poses, (1024,1024,hwf[2]), K, render_kwargs_test)\n",
    "    print('Done, saving', rgbs.shape, disps.shape)\n",
    "    moviebase = os.path.join(basedir, expname, '{}_spiral_{:06d}_'.format(expname, i))\n",
    "    imageio.mimwrite(moviebase + 'rgb.mp4', to8b(rgbs), fps=30, quality=8)\n",
    "    imageio.mimwrite(moviebase + 'disp.mp4', to8b(disps / np.max(disps)), fps=30, quality=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a18af33-81b7-4996-9466-61feb3c88689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
